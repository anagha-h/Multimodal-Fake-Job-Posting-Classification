{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36105cf",
   "metadata": {},
   "source": [
    "\n",
    "# AlexNet Fine-Tuning Classifier (Lightning)\n",
    "\n",
    "This notebook fine-tunes **AlexNet (pretrained on ImageNet)** for image classification using **PyTorch Lightning**.\n",
    "\n",
    "**Highlights**\n",
    "- Safe dataset that skips unreadable/corrupt images\n",
    "- `CrossEntropyLoss` + `AdamW`\n",
    "- Callbacks: **EarlyStopping**, **ModelCheckpoint**, **LearningRateMonitor**\n",
    "- Optional **feature-extraction** cell for 4096-D embeddings (fusion-ready)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0214784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, csv, math, random, json\n",
    "from pathlib import Path\n",
    "from typing import Optional, Any, Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# ---- Hyperparameters ----\n",
    "CSV_PATH = \"Projects/FakeJob/fake_job_postings.csv\"    # path to your csv with columns: image_path,label\n",
    "IMG_ROOT = \"Projects/FakeJob/images\"                          # base folder joined with image_path if needed\n",
    "NUM_CLASSES = 2                         # change if needed\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 3\n",
    "LR = 1e-4\n",
    "NUM_WORKERS = 2\n",
    "VAL_SPLIT = 0.2                         # split % for validation if no explicit split columns\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, matthews_corrcoef, balanced_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cdbbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class JobImageDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str = \".\", tfm=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image_path']\n",
    "        label = int(row['label'])\n",
    "\n",
    "        # construct full path if needed\n",
    "        full_path = img_path if os.path.isabs(img_path) else os.path.join(self.img_root, img_path)\n",
    "        try:\n",
    "            with Image.open(full_path) as im:\n",
    "                im = im.convert('RGB')\n",
    "            if self.tfm is not None:\n",
    "                im = self.tfm(im)\n",
    "            return im, label\n",
    "        except Exception as e:\n",
    "            # Return a None sample so collate can drop it\n",
    "            return None\n",
    "\n",
    "def collate_skip_none(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    x, y = zip(*batch)\n",
    "    return torch.stack(x, dim=0), torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be00915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['0', '1']\n",
      "Class counts: {0: 5579, 1: 856}\n",
      "Class weights (inv freq): [1.1534325147875963, 7.517523364485982]\n",
      "Stratified Train/Val sizes: 5148 1287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Data loading: ImageFolder preferred, CSV fallback =====\n",
    "# Set this to True to use images/0 and images/1 structure directly.\n",
    "USE_IMAGEFOLDER = True\n",
    "IMAGE_ROOT = \"Projects/FakeJob/images\"   # expects subfolders '0', '1', ... for class labels\n",
    "\n",
    "# Standard ImageNet mean/std and input size for AlexNet (224x224)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "val_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "CLASS_WEIGHTS = None  # will be a list/np.array like [w0, w1, ...]\n",
    "\n",
    "if USE_IMAGEFOLDER:\n",
    "    # --- ImageFolder mode (no CSV needed) ---\n",
    "    from torchvision import datasets\n",
    "\n",
    "    base_ds = datasets.ImageFolder(root=IMAGE_ROOT, transform=train_tfm)\n",
    "    print(\"Classes detected:\", base_ds.classes)\n",
    "\n",
    "    # Compute class counts and weights (inverse frequency)\n",
    "    targets = [y for _, y in base_ds.samples]\n",
    "    counts = Counter(targets)\n",
    "    total = sum(counts.values())\n",
    "    CLASS_WEIGHTS = [total / counts[i] for i in range(len(counts))]\n",
    "    print(\"Class counts:\", dict(counts))\n",
    "    print(\"Class weights (inv freq):\", CLASS_WEIGHTS)\n",
    "\n",
    "    # Stratified split\n",
    "    import numpy as np\n",
    "    targets_np = np.array(targets)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SPLIT, random_state=SEED)\n",
    "    train_idx, val_idx = next(sss.split(np.zeros(len(targets_np)), targets_np))\n",
    "\n",
    "    train_ds = torch.utils.data.Subset(base_ds, train_idx)\n",
    "    val_ds   = torch.utils.data.Subset(base_ds, val_idx)\n",
    "    # Ensure val uses val transforms\n",
    "    val_ds.dataset.transform = val_tfm\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    print(\"Stratified Train/Val sizes:\", len(train_ds), len(val_ds))\n",
    "else:\n",
    "    # --- CSV fallback (expects CSV with columns: image_path,label) ---\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    assert {'image_path','label'}.issubset(set(df.columns)), \"CSV must contain columns: image_path,label\"\n",
    "\n",
    "    # Compute class weights\n",
    "    counts = Counter(df['label'].astype(int).tolist())\n",
    "    total = sum(counts.values())\n",
    "    CLASS_WEIGHTS = [total / counts[i] for i in sorted(counts.keys())]\n",
    "    print(\"Class counts:\", dict(counts))\n",
    "    print(\"Class weights (inv freq):\", CLASS_WEIGHTS)\n",
    "\n",
    "    # Stratified split\n",
    "    import numpy as np\n",
    "    y = df['label'].astype(int).to_numpy()\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SPLIT, random_state=SEED)\n",
    "    train_idx, val_idx = next(sss.split(np.zeros(len(y)), y))\n",
    "\n",
    "    df_train = df.iloc[train_idx].copy().reset_index(drop=True)\n",
    "    df_val   = df.iloc[val_idx].copy().reset_index(drop=True)\n",
    "\n",
    "    print(\"Stratified Train/Val sizes:\", len(df_train), len(df_val))\n",
    "\n",
    "    train_ds = JobImageDataset(df_train, img_root=IMG_ROOT, tfm=train_tfm)\n",
    "    val_ds   = JobImageDataset(df_val,   img_root=IMG_ROOT, tfm=val_tfm)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_skip_none)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_skip_none)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041e005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_alexnet_classifier(num_classes=2, pretrained=True):\n",
    "    # For torchvision >= 0.13, use Weights enums\n",
    "    weights = models.AlexNet_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = models.alexnet(weights=weights)\n",
    "    # Replace final classifier layer\n",
    "    in_feats = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_feats, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d285a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Optional\n",
    "\n",
    "class AlexNetLitModule(L.LightningModule):\n",
    "    def __init__(self, num_classes: int = NUM_CLASSES, lr: float = LR, class_weights: Optional[list] = None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = build_alexnet_classifier(num_classes=num_classes, pretrained=True)\n",
    "\n",
    "        # class weights buffer\n",
    "        if class_weights is not None:\n",
    "            cw = torch.as_tensor(class_weights, dtype=torch.float32)\n",
    "            self.register_buffer(\"class_weights\", cw)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        self.lr = lr\n",
    "\n",
    "        # caches for validation metrics\n",
    "        self._val_targets, self._val_probs, self._val_preds = [], [], []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if batch is None:\n",
    "            return None\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\",  acc,  on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self._val_targets, self._val_probs, self._val_preds = [], [], []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch is None:\n",
    "            return None\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1] if logits.size(1) > 1 else torch.sigmoid(logits).squeeze(-1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self._val_targets.extend(y.detach().cpu().tolist())\n",
    "        self._val_preds.extend(preds.detach().cpu().tolist())\n",
    "        self._val_probs.extend(probs.detach().cpu().tolist())\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\",  acc,  on_epoch=True, prog_bar=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self._val_targets:\n",
    "            return\n",
    "        import numpy as np\n",
    "        y_true  = np.array(self._val_targets, dtype=int)\n",
    "        y_pred  = np.array(self._val_preds,   dtype=int)\n",
    "        y_score = np.array(self._val_probs,   dtype=float)\n",
    "\n",
    "        # ranking metrics\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            roc_auc = float(\"nan\")\n",
    "        try:\n",
    "            pr_auc  = average_precision_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            pr_auc = float(\"nan\")\n",
    "\n",
    "        # thresholded metrics (fraud class = 1)\n",
    "        try:\n",
    "            f1   = f1_score(y_true, y_pred, pos_label=1)\n",
    "            prec = precision_score(y_true, y_pred, pos_label=1)\n",
    "            rec  = recall_score(y_true, y_pred, pos_label=1)\n",
    "            mcc  = matthews_corrcoef(y_true, y_pred)\n",
    "            bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "        except Exception:\n",
    "            f1 = prec = rec = mcc = bal_acc = float(\"nan\")\n",
    "\n",
    "        self.log(\"PR_AUC\",        pr_auc,   prog_bar=True,  on_epoch=True)\n",
    "        self.log(\"ROC_AUC\",       roc_auc,  prog_bar=False, on_epoch=True)\n",
    "        self.log(\"F1_fraud\",      f1,       prog_bar=True,  on_epoch=True)\n",
    "        self.log(\"Prec_fraud\",    prec,     prog_bar=False, on_epoch=True)\n",
    "        self.log(\"Rec_fraud\",     rec,      prog_bar=False, on_epoch=True)\n",
    "        self.log(\"MCC\",           mcc,      prog_bar=False, on_epoch=True)\n",
    "        self.log(\"BalancedAcc\",   bal_acc,  prog_bar=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa0b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | AlexNet          | 57.0 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "57.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.048   Total estimated model params size (MB)\n",
      "25        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 161/161 [01:17<00:00,  2.09it/s, v_num=4, train_loss_step=0.504, train_acc_step=0.786]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏         | 1/41 [00:00<00:08,  4.46it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▍         | 2/41 [00:00<00:08,  4.73it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▋         | 3/41 [00:00<00:07,  4.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|▉         | 4/41 [00:00<00:07,  4.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▏        | 5/41 [00:01<00:07,  4.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|█▍        | 6/41 [00:01<00:07,  4.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|█▋        | 7/41 [00:01<00:06,  4.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█▉        | 8/41 [00:01<00:06,  5.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|██▏       | 9/41 [00:01<00:06,  4.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|██▍       | 10/41 [00:02<00:06,  4.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|██▋       | 11/41 [00:02<00:06,  4.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|██▉       | 12/41 [00:02<00:06,  4.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|███▏      | 13/41 [00:02<00:06,  4.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 14/41 [00:03<00:06,  4.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|███▋      | 15/41 [00:03<00:06,  4.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███▉      | 16/41 [00:03<00:05,  4.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████▏     | 17/41 [00:04<00:05,  4.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████▍     | 18/41 [00:04<00:05,  4.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████▋     | 19/41 [00:04<00:05,  4.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████▉     | 20/41 [00:04<00:05,  4.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|█████     | 21/41 [00:05<00:04,  4.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████▎    | 22/41 [00:05<00:04,  4.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████▌    | 23/41 [00:05<00:04,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▊    | 24/41 [00:05<00:04,  4.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████    | 25/41 [00:06<00:03,  4.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████▎   | 26/41 [00:06<00:03,  4.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 27/41 [00:06<00:03,  4.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████▊   | 28/41 [00:07<00:03,  3.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████   | 29/41 [00:07<00:03,  4.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 30/41 [00:07<00:02,  3.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 31/41 [00:07<00:02,  3.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 32/41 [00:08<00:02,  3.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 33/41 [00:08<00:02,  3.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 34/41 [00:08<00:01,  3.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 35/41 [00:08<00:01,  3.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 36/41 [00:09<00:01,  3.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████ | 37/41 [00:09<00:01,  3.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 38/41 [00:09<00:00,  3.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 39/41 [00:09<00:00,  3.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|█████████▊| 40/41 [00:10<00:00,  3.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 41/41 [00:10<00:00,  3.99it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/161 [00:00<?, ?it/s, v_num=4, train_loss_step=0.504, train_acc_step=0.786, val_loss=0.505, val_acc=0.693, PR_AUC=0.625, F1_fraud=0.428, train_loss_epoch=0.559, train_acc_epoch=0.766]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 161/161 [01:27<00:00,  1.83it/s, v_num=4, train_loss_step=0.387, train_acc_step=0.929, val_loss=0.505, val_acc=0.693, PR_AUC=0.625, F1_fraud=0.428, train_loss_epoch=0.559, train_acc_epoch=0.766] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏         | 1/41 [00:00<00:09,  4.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▍         | 2/41 [00:00<00:08,  4.65it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▋         | 3/41 [00:00<00:07,  4.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|▉         | 4/41 [00:00<00:07,  4.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▏        | 5/41 [00:01<00:07,  4.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|█▍        | 6/41 [00:01<00:07,  4.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|█▋        | 7/41 [00:01<00:06,  4.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█▉        | 8/41 [00:01<00:06,  5.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|██▏       | 9/41 [00:01<00:06,  4.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|██▍       | 10/41 [00:02<00:06,  4.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|██▋       | 11/41 [00:02<00:06,  4.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|██▉       | 12/41 [00:02<00:06,  4.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|███▏      | 13/41 [00:02<00:06,  4.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 14/41 [00:03<00:06,  4.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|███▋      | 15/41 [00:03<00:06,  4.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███▉      | 16/41 [00:03<00:05,  4.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████▏     | 17/41 [00:04<00:05,  4.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████▍     | 18/41 [00:04<00:05,  4.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████▋     | 19/41 [00:04<00:05,  4.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████▉     | 20/41 [00:04<00:05,  4.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|█████     | 21/41 [00:05<00:04,  4.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████▎    | 22/41 [00:05<00:04,  4.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████▌    | 23/41 [00:05<00:04,  4.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▊    | 24/41 [00:05<00:04,  4.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████    | 25/41 [00:06<00:03,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████▎   | 26/41 [00:06<00:03,  4.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 27/41 [00:06<00:03,  4.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████▊   | 28/41 [00:06<00:03,  4.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████   | 29/41 [00:07<00:02,  4.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 30/41 [00:07<00:02,  4.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 31/41 [00:07<00:02,  4.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 32/41 [00:08<00:02,  3.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 33/41 [00:08<00:01,  4.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 34/41 [00:08<00:01,  3.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 35/41 [00:08<00:01,  3.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 36/41 [00:09<00:01,  3.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████ | 37/41 [00:09<00:01,  3.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 38/41 [00:09<00:00,  3.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 39/41 [00:09<00:00,  3.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|█████████▊| 40/41 [00:10<00:00,  3.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 41/41 [00:10<00:00,  4.03it/s]\u001b[A\n",
      "Epoch 2:   0%|          | 0/161 [00:00<?, ?it/s, v_num=4, train_loss_step=0.387, train_acc_step=0.929, val_loss=0.448, val_acc=0.860, PR_AUC=0.671, F1_fraud=0.581, train_loss_epoch=0.403, train_acc_epoch=0.823]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 161/161 [01:27<00:00,  1.84it/s, v_num=4, train_loss_step=0.293, train_acc_step=0.893, val_loss=0.448, val_acc=0.860, PR_AUC=0.671, F1_fraud=0.581, train_loss_epoch=0.403, train_acc_epoch=0.823] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏         | 1/41 [00:00<00:09,  4.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▍         | 2/41 [00:00<00:08,  4.64it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▋         | 3/41 [00:00<00:07,  4.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|▉         | 4/41 [00:00<00:07,  4.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▏        | 5/41 [00:01<00:07,  4.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|█▍        | 6/41 [00:01<00:07,  4.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|█▋        | 7/41 [00:01<00:06,  4.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█▉        | 8/41 [00:01<00:06,  4.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|██▏       | 9/41 [00:01<00:06,  4.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|██▍       | 10/41 [00:02<00:06,  4.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|██▋       | 11/41 [00:02<00:06,  4.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|██▉       | 12/41 [00:02<00:06,  4.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|███▏      | 13/41 [00:02<00:06,  4.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 14/41 [00:03<00:06,  4.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|███▋      | 15/41 [00:03<00:06,  4.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███▉      | 16/41 [00:03<00:05,  4.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████▏     | 17/41 [00:04<00:05,  4.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████▍     | 18/41 [00:04<00:05,  4.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████▋     | 19/41 [00:04<00:05,  4.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████▉     | 20/41 [00:04<00:05,  4.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|█████     | 21/41 [00:05<00:04,  4.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████▎    | 22/41 [00:05<00:04,  4.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████▌    | 23/41 [00:05<00:04,  4.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▊    | 24/41 [00:05<00:04,  4.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████    | 25/41 [00:06<00:03,  4.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████▎   | 26/41 [00:06<00:03,  3.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 27/41 [00:06<00:03,  4.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████▊   | 28/41 [00:07<00:03,  3.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████   | 29/41 [00:07<00:03,  3.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 30/41 [00:07<00:02,  3.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 31/41 [00:07<00:02,  3.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 32/41 [00:08<00:02,  3.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 33/41 [00:08<00:02,  3.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 34/41 [00:08<00:01,  3.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 35/41 [00:08<00:01,  3.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 36/41 [00:09<00:01,  3.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████ | 37/41 [00:09<00:01,  3.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 38/41 [00:09<00:00,  3.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 39/41 [00:09<00:00,  3.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|█████████▊| 40/41 [00:10<00:00,  3.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 41/41 [00:10<00:00,  3.98it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 161/161 [01:49<00:00,  1.47it/s, v_num=4, train_loss_step=0.293, train_acc_step=0.893, val_loss=0.536, val_acc=0.765, PR_AUC=0.660, F1_fraud=0.486, train_loss_epoch=0.339, train_acc_epoch=0.848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 161/161 [01:50<00:00,  1.46it/s, v_num=4, train_loss_step=0.293, train_acc_step=0.893, val_loss=0.536, val_acc=0.765, PR_AUC=0.660, F1_fraud=0.486, train_loss_epoch=0.339, train_acc_epoch=0.848]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "monitors_metric = \"PR_AUC\"\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    monitor=monitors_metric,\n",
    "    mode=\"max\",\n",
    "    save_last=True,\n",
    "    save_top_k=1,\n",
    "    filename=\"alexnet-{epoch:02d}-{val_acc:.4f}\"\n",
    ")\n",
    "early_cb = EarlyStopping(\n",
    "    monitor=monitors_metric, \n",
    "    mode=\"max\", \n",
    "    patience=3\n",
    ")\n",
    "lrmon = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# precision/accelerator/devices logic\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "devices = 1\n",
    "precision = \"16-mixed\" if torch.cuda.is_available() else \"32-true\"\n",
    "\n",
    "logger = CSVLogger(save_dir=\"logs\", name=\"alexnet_finetune\")\n",
    "\n",
    "model = AlexNetLitModule(num_classes=NUM_CLASSES, lr=LR, class_weights=CLASS_WEIGHTS)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    callbacks=[checkpoint_cb, early_cb, lrmon],\n",
    "    log_every_n_steps=20,\n",
    "    precision=precision,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ec6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val_predictions_alexnet.csv with 1287 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Export validation predictions to CSV ---\n",
    "model.eval()\n",
    "preds_all = []\n",
    "gts_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        x, y = batch\n",
    "        logits = model(x.to(model.device))\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n",
    "        gt = y.numpy().tolist()\n",
    "        preds_all.extend(pred)\n",
    "        gts_all.extend(gt)\n",
    "\n",
    "out_df = pd.DataFrame({\"gt\": gts_all, \"pred\": preds_all})\n",
    "out_path = \"val_predictions_alexnet.csv\"\n",
    "out_df.to_csv(out_path, index=False)\n",
    "print(f\"Saved {out_path} with {len(out_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee198c9",
   "metadata": {},
   "source": [
    "## Optional: Extract 4096-D AlexNet features for multimodal fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ca5d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature arrays under: alexnet_features\n",
      "Train feats: (5148, 4096) Val feats: (1287, 4096)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell turns AlexNet into a 4096-D feature extractor by dropping the last FC layer.\n",
    "# It saves numpy arrays: features (N,4096) and labels (N,)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def build_alexnet_feature_extractor(pretrained=True):\n",
    "    weights = models.AlexNet_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = models.alexnet(weights=weights)\n",
    "    # Remove the last layer to get 4096-d features\n",
    "    model.classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    return model.eval()\n",
    "\n",
    "def extract_features(loader: DataLoader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    fe = build_alexnet_feature_extractor(pretrained=True).to(device).eval()\n",
    "    feats, labs = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "            x, y = batch\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            v = fe(x).cpu().numpy()  # [B,4096]\n",
    "            feats.append(v); labs.extend(y.numpy().tolist())\n",
    "    feats = np.concatenate(feats, axis=0)\n",
    "    labs = np.array(labs)\n",
    "    return feats, labs\n",
    "\n",
    "feat_dir = \"alexnet_features\"\n",
    "os.makedirs(feat_dir, exist_ok=True)\n",
    "\n",
    "train_feats, train_labels = extract_features(train_loader)\n",
    "val_feats,   val_labels   = extract_features(val_loader)\n",
    "\n",
    "np.save(os.path.join(feat_dir, \"train_alexnet_feats.npy\"), train_feats)\n",
    "np.save(os.path.join(feat_dir, \"train_labels.npy\"),       train_labels)\n",
    "np.save(os.path.join(feat_dir, \"val_alexnet_feats.npy\"),  val_feats)\n",
    "np.save(os.path.join(feat_dir, \"val_labels.npy\"),         val_labels)\n",
    "\n",
    "print(\"Saved feature arrays under:\", feat_dir)\n",
    "print(\"Train feats:\", train_feats.shape, \"Val feats:\", val_feats.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
